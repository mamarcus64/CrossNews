{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "random.seed(8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = json.load(open('data/crossnews_gold.json', 'r', encoding='utf-8'))\n",
    "silver = json.load(open('data/crossnews_silver.json', 'r', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_authors = {}\n",
    "silver_authors = {}\n",
    "\n",
    "for docs, authors in [\n",
    "    (gold, gold_authors),\n",
    "    (silver, silver_authors)\n",
    "]:\n",
    "    for doc in docs:\n",
    "        author = doc['author']\n",
    "        authors[author] = authors.get(author, []) + [doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167404 337\n",
      "1202716 5665\n"
     ]
    }
   ],
   "source": [
    "print(len(gold), len(gold_authors))\n",
    "print(len(silver), len(silver_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_thresholds(authors, threshold, genre=None, filter=None):\n",
    "    result = set()\n",
    "    if filter is None:\n",
    "        filter = lambda x: True\n",
    "    for author_id, author_docs in authors.items():\n",
    "        doc_num = sum([1 if filter(doc) and (genre is None or doc['genre'] == genre) else 0 for doc in author_docs])\n",
    "        if doc_num >= threshold:\n",
    "            result.add(author_id)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(authors, author_id, genre=None):\n",
    "    author_docs = [doc for doc in authors[author_id] if genre is None or doc['genre'] == genre]\n",
    "    doc = random.choice(author_docs)\n",
    "    print('Document genre:', doc['genre'])\n",
    "    print('Document length:', len(doc['text']))\n",
    "    print(doc['text'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 5614\n"
     ]
    }
   ],
   "source": [
    "def length_filter(doc, length=100):\n",
    "    return len(doc['text']) >= length\n",
    "\n",
    "gold_filtered = doc_thresholds(gold_authors, 100, genre='Tweet', filter=length_filter)\n",
    "silver_filtered = doc_thresholds(silver_authors, 1, genre='Article', filter=length_filter)\n",
    "print(len(gold_filtered), len(silver_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_stats(values):\n",
    "    return f'total: {round(sum(values), 0)} count: {len(values)} mean: {round(np.mean(values), 3)} quartiles: {round(np.percentile(values, 25), 3)}/{round(np.percentile(values, 50), 3)}/{round(np.percentile(values, 75), 3)} std: {round(np.std(values), 3)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_author_statistics(authors):\n",
    "    print(f'Number of authors: {len(authors)}')\n",
    "    articles, tweets = [], []\n",
    "    for author in authors.values():\n",
    "        if len([len(doc['text']) for doc in author if doc['genre'] == 'Article']) > 0:\n",
    "            articles.append([len(doc['text']) for doc in author if doc['genre'] == 'Article'])\n",
    "        if len([len(doc['text']) for doc in author if doc['genre'] == 'Tweet']) > 0:\n",
    "            tweets.append([len(doc['text']) for doc in author if doc['genre'] == 'Tweet'])\n",
    "        \n",
    "    print('Articles per author: ' + list_stats([len(x) for x in articles]))\n",
    "    print('Chars per article per author: ' + list_stats([sum(x) / len(x) if len(x) > 0 else 0 for x in articles]))\n",
    "    print('Tweets per author: ' + list_stats([len(x) for x in tweets]))\n",
    "    print('Chars per tweet per author: ' + list_stats([sum(x) / len(x) if len(x) > 0 else 0 for x in tweets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 337\n",
      "Articles per author: total: 58563 count: 337 mean: 173.777 quartiles: 100.0/100.0/250.0 std: 160.576\n",
      "Chars per article per author: total: 1149009.0 count: 337 mean: 3409.523 quartiles: 267.45/374.27/5753.864 std: 4751.575\n",
      "Tweets per author: total: 108841 count: 337 mean: 322.97 quartiles: 100.0/100.0/600.0 std: 260.896\n",
      "Chars per tweet per author: total: 50401.0 count: 337 mean: 149.558 quartiles: 94.492/141.16/211.67 std: 59.551\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(gold_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_documents(authors, threshold, method='random'):\n",
    "    authors = copy.deepcopy(authors)\n",
    "    new_authors = {author: [] for author in authors.keys()}\n",
    "    for author, old_docs in authors.items():\n",
    "        articles = [doc for doc in old_docs if doc['genre'] == 'Article']\n",
    "        tweets = [doc for doc in old_docs if doc['genre'] == 'Tweet']\n",
    "        \n",
    "        for docs in [articles, tweets]:\n",
    "            if method == 'random':\n",
    "                random.shuffle(docs)\n",
    "            elif method == 'greedy':\n",
    "                docs = sorted(docs, key=lambda x: len(x['text']), reverse=True)\n",
    "            new_doc = None\n",
    "            for doc in docs:\n",
    "                if new_doc is None:\n",
    "                    new_doc = doc\n",
    "                else:\n",
    "                    new_doc['text'] += f'<new> {doc[\"text\"]}'\n",
    "                if len(new_doc['text']) >= threshold:\n",
    "                    new_authors[author].append(new_doc)\n",
    "                    new_doc = None\n",
    "    return new_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 5665\n",
      "Articles per author: total: 158984 count: 5614 mean: 28.319 quartiles: 2.0/4.0/17.0 std: 112.14\n",
      "Chars per article per author: total: 42858989.0 count: 5614 mean: 7634.305 quartiles: 3158.0/5503.0/8810.329 std: 8183.977\n",
      "Tweets per author: total: 1043732 count: 1925 mean: 542.198 quartiles: 500.0/600.0/600.0 std: 371.168\n",
      "Chars per tweet per author: total: 236446.0 count: 1925 mean: 122.829 quartiles: 91.49/116.665/149.153 std: 42.284\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(silver_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 5665\n",
      "Articles per author: total: 158736 count: 5610 mean: 28.295 quartiles: 2.0/4.0/17.0 std: 111.949\n",
      "Chars per article per author: total: 42895067.0 count: 5610 mean: 7646.179 quartiles: 3167.466/5512.055/8825.95 std: 8184.857\n",
      "Tweets per author: total: 237174 count: 1900 mean: 124.828 quartiles: 80.0/117.0/153.25 std: 101.02\n",
      "Chars per tweet per author: total: 1078316.0 count: 1900 mean: 567.535 quartiles: 559.752/568.952/576.468 std: 13.842\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(stack_documents(silver_authors, 500, method='greedy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 337\n",
      "Articles per author: total: 58563 count: 337 mean: 173.777 quartiles: 100.0/100.0/250.0 std: 160.576\n",
      "Chars per article per author: total: 1149009.0 count: 337 mean: 3409.523 quartiles: 267.45/374.27/5753.864 std: 4751.575\n",
      "Tweets per author: total: 108841 count: 337 mean: 322.97 quartiles: 100.0/100.0/600.0 std: 260.896\n",
      "Chars per tweet per author: total: 50401.0 count: 337 mean: 149.558 quartiles: 94.492/141.16/211.67 std: 59.551\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(gold_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 337\n",
      "Articles per author: total: 48219 count: 337 mean: 143.083 quartiles: 43.0/54.0/249.0 std: 175.025\n",
      "Chars per article per author: total: 1221457.0 count: 337 mean: 3624.501 quartiles: 625.6/690.919/5880.651 std: 4646.772\n",
      "Tweets per author: total: 25228 count: 337 mean: 74.861 quartiles: 34.0/41.0/115.0 std: 59.273\n",
      "Chars per tweet per author: total: 194301.0 count: 337 mean: 576.561 quartiles: 564.259/575.409/588.7 std: 18.603\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(stack_documents(gold_authors, 500, method='greedy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document genre: Article\n",
      "Document length: 7362\n",
      "The commander of the scandal-plagued California National Guard steps down\n",
      "The head of the California National Guard, who has presided over a series of scandals during the last 3½ years, will retire at the end of the month, Gov. <PERSON>’s office confirmed Monday.\n",
      "Maj. Gen. <PERSON>’s departure comes\n"
     ]
    }
   ],
   "source": [
    "# print_example(gold_authors, random.choice(tuple(gold_filtered)), genre='Tweet')\n",
    "print_example(silver_authors, random.choice(tuple(silver_filtered)), genre='Article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_golds = stack_documents(gold_authors, 500, method='greedy')\n",
    "stacked_silvers = stack_documents(silver_authors, 500, method='greedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_verification_pairs(data, first_genre, second_genre, add_imbalanced=False):\n",
    "    data = copy.deepcopy(data)\n",
    "    first_docs = {\n",
    "        author_name: [doc for doc in author_docs if doc['genre'] == first_genre]\n",
    "            for author_name, author_docs in data.items()\n",
    "    }\n",
    "    if first_genre == second_genre:\n",
    "        second_docs = first_docs\n",
    "    else:\n",
    "        second_docs = {\n",
    "            author_name: [doc for doc in author_docs if doc['genre'] == second_genre]\n",
    "                for author_name, author_docs in data.items()\n",
    "        }\n",
    "        \n",
    "    overflow_first, overflow_second = [], []\n",
    "    \n",
    "    for author in data.keys():\n",
    "        random.shuffle(first_docs[author])\n",
    "        random.shuffle(second_docs[author])\n",
    "        \n",
    "        if len(first_docs[author]) == 0 or len(second_docs[author]) == 0:\n",
    "            overflow_first.extend(first_docs[author])\n",
    "            overflow_second.extend(second_docs[author])\n",
    "            \n",
    "            del first_docs[author]\n",
    "            del second_docs[author]\n",
    "    \n",
    "    # each pair is a 3-tuple of (label, first_text, second_text), where label == 0 if different authors and 1 if same author\n",
    "    pairs = []\n",
    "   \n",
    "    next_pick = 'same'\n",
    "    while len(first_docs) > 1:\n",
    "        # pick authors for next pair\n",
    "        \n",
    "        \n",
    "        first_author = sorted(list(first_docs.keys()), key=lambda author: len(first_docs[author]), reverse=True)[0]\n",
    "        second_author = first_author\n",
    "        if next_pick == 'diff':\n",
    "            # second_author = sorted(list(first_docs.keys()), key=lambda author: len(first_docs[author]), reverse=True)[1]\n",
    "            while second_author == first_author:\n",
    "                second_author = random.choice(list(first_docs.keys()))\n",
    "        \n",
    "        if len(first_docs[first_author]) == 0 or len(second_docs[second_author]) == 0:\n",
    "            print(first_author, second_author, len(first_docs[first_author]), len(second_docs[second_author]))\n",
    "        pairs.append((1 if next_pick == 'same' else 0, first_docs[first_author].pop()['text'], second_docs[second_author].pop()['text']))\n",
    "        \n",
    "        delete_threshold = 0 if first_genre != second_genre else 1\n",
    "        \n",
    "        # now, if either list is empty (or list has one element and first_genre == second_genre), delete from both docs dicts\n",
    "        if len(first_docs[first_author]) <= delete_threshold:\n",
    "            del first_docs[first_author]\n",
    "            if first_genre != second_genre:\n",
    "                overflow_second.extend(second_docs[first_author])\n",
    "                del second_docs[first_author]\n",
    "        if second_author in first_docs and len(first_docs[second_author]) <= delete_threshold:\n",
    "            del second_docs[second_author]\n",
    "            if first_genre != second_genre:\n",
    "                overflow_first.extend(first_docs[second_author])\n",
    "                del first_docs[second_author]\n",
    "        if first_author in second_docs and len(second_docs[first_author]) <= delete_threshold:\n",
    "            del first_docs[first_author]\n",
    "            if first_genre != second_genre:\n",
    "                overflow_second.extend(second_docs[first_author])\n",
    "                del second_docs[first_author]\n",
    "        if second_author in second_docs and len(second_docs[second_author]) <= delete_threshold:\n",
    "            del second_docs[second_author]\n",
    "            if first_genre != second_genre:\n",
    "                overflow_first.extend(first_docs[second_author])\n",
    "                del first_docs[second_author]\n",
    "                \n",
    "        # alternate pair type\n",
    "        next_pick = 'diff' if next_pick == 'same' else 'same'\n",
    "        \n",
    "    if add_imbalanced and first_genre != second_genre:\n",
    "        # guaranteed to be diff pairs b/c overflow is added when length of one genre == 0\n",
    "        random.shuffle(overflow_first)\n",
    "        random.shuffle(overflow_second)\n",
    "        for i in range(min(len(overflow_first), len(overflow_second))):\n",
    "            pairs.append((0, overflow_first[i]['text'], overflow_second[i]['text']))\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pair_stats(pairs, save=None):\n",
    "    print(f'Total pairs: {len(pairs)}; same-pair percent: {sum([pair[0] for pair in pairs]) / len(pairs)}')\n",
    "    if save:\n",
    "        print(f'Saving to {save}.')\n",
    "        columns = ['label', 'text0', 'text1']\n",
    "        df = pd.DataFrame(pairs, columns=columns)\n",
    "        df.to_csv(save, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 12470; same-pair percent: 0.5\n",
      "Saving to pairs/test_X_X.csv.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('pairs')\n",
    "pairs = create_verification_pairs(stacked_golds, 'Tweet', 'Tweet')\n",
    "print_pair_stats(pairs, save='pairs/test_X_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 24675; same-pair percent: 0.5000202634245188\n",
      "Saving to pairs/test_Article_X.csv.\n"
     ]
    }
   ],
   "source": [
    "pairs = create_verification_pairs(stacked_golds, 'Article', 'Tweet')\n",
    "print_pair_stats(pairs, save='pairs/test_Article_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 23968; same-pair percent: 0.5\n",
      "Saving to pairs/test_Article_Article.csv.\n"
     ]
    }
   ],
   "source": [
    "pairs = create_verification_pairs(stacked_golds, 'Article', 'Article')\n",
    "print_pair_stats(pairs, save='pairs/test_Article_Article.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 51859; same-pair percent: 0.5000096415279893\n",
      "Saving to pairs/train_Article_X.csv.\n"
     ]
    }
   ],
   "source": [
    "pairs = create_verification_pairs(stacked_silvers, 'Article', 'Tweet')\n",
    "print_pair_stats(pairs, save='pairs/train_Article_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 127973; same-pair percent: 0.20340228016847303\n",
      "Saving to pairs/train_Article_X_imbalanced.csv.\n"
     ]
    }
   ],
   "source": [
    "pairs = create_verification_pairs(stacked_silvers, 'Article', 'Tweet', add_imbalanced=True)\n",
    "print_pair_stats(pairs, save='pairs/train_Article_X_imbalanced.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
