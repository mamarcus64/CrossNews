{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "random.seed(8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = json.load(open('data/crossnews_gold.json', 'r', encoding='utf-8'))\n",
    "silver = json.load(open('data/crossnews_silver.json', 'r', encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_authors = {}\n",
    "silver_authors = {}\n",
    "\n",
    "for docs, authors in [\n",
    "    (gold, gold_authors),\n",
    "    (silver, silver_authors)\n",
    "]:\n",
    "    for doc in docs:\n",
    "        author = doc['author']\n",
    "        authors[author] = authors.get(author, []) + [doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167404 337\n",
      "1202716 5665\n"
     ]
    }
   ],
   "source": [
    "print(len(gold), len(gold_authors))\n",
    "print(len(silver), len(silver_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_thresholds(authors, threshold, genre=None, filter=None):\n",
    "    result = set()\n",
    "    if filter is None:\n",
    "        filter = lambda x: True\n",
    "    for author_id, author_docs in authors.items():\n",
    "        doc_num = sum([1 if filter(doc) and (genre is None or doc['genre'] == genre) else 0 for doc in author_docs])\n",
    "        if doc_num >= threshold:\n",
    "            result.add(author_id)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(authors, author_id, genre=None):\n",
    "    author_docs = [doc for doc in authors[author_id] if genre is None or doc['genre'] == genre]\n",
    "    doc = random.choice(author_docs)\n",
    "    print('Document genre:', doc['genre'])\n",
    "    print('Document length:', len(doc['text']))\n",
    "    print(doc['text'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237 5614\n"
     ]
    }
   ],
   "source": [
    "def length_filter(doc, length=100):\n",
    "    return len(doc['text']) >= length\n",
    "\n",
    "gold_filtered = doc_thresholds(gold_authors, 100, genre='Tweet', filter=length_filter)\n",
    "silver_filtered = doc_thresholds(silver_authors, 1, genre='Article', filter=length_filter)\n",
    "print(len(gold_filtered), len(silver_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_stats(values):\n",
    "    return f'total: {round(sum(values), 0)} count: {len(values)} mean: {round(np.mean(values), 3)} quartiles: {round(np.percentile(values, 25), 3)}/{round(np.percentile(values, 50), 3)}/{round(np.percentile(values, 75), 3)} std: {round(np.std(values), 3)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_author_statistics(authors):\n",
    "    print(f'Number of authors: {len(authors)}')\n",
    "    articles, tweets = [], []\n",
    "    for author in authors.values():\n",
    "        if len([len(doc['text']) for doc in author if doc['genre'] == 'Article']) > 0:\n",
    "            articles.append([len(doc['text']) for doc in author if doc['genre'] == 'Article'])\n",
    "        if len([len(doc['text']) for doc in author if doc['genre'] == 'Tweet']) > 0:\n",
    "            tweets.append([len(doc['text']) for doc in author if doc['genre'] == 'Tweet'])\n",
    "        \n",
    "    print('Articles per author: ' + list_stats([len(x) for x in articles]))\n",
    "    print('Chars per article per author: ' + list_stats([sum(x) / len(x) if len(x) > 0 else 0 for x in articles]))\n",
    "    print('Tweets per author: ' + list_stats([len(x) for x in tweets]))\n",
    "    print('Chars per tweet per author: ' + list_stats([sum(x) / len(x) if len(x) > 0 else 0 for x in tweets]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 337\n",
      "Articles per author: total: 58563 count: 337 mean: 173.777 quartiles: 100.0/100.0/250.0 std: 160.576\n",
      "Chars per article per author: total: 1149009.0 count: 337 mean: 3409.523 quartiles: 267.45/374.27/5753.864 std: 4751.575\n",
      "Tweets per author: total: 108841 count: 337 mean: 322.97 quartiles: 100.0/100.0/600.0 std: 260.896\n",
      "Chars per tweet per author: total: 50401.0 count: 337 mean: 149.558 quartiles: 94.492/141.16/211.67 std: 59.551\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(gold_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_documents(authors, threshold, upper_char_limit=2500, method='random', is_test=False):\n",
    "    authors = copy.deepcopy(authors)\n",
    "    new_authors = {author: [] for author in authors.keys()}\n",
    "    for author, old_docs in authors.items():\n",
    "        articles = [doc for doc in old_docs if doc['genre'] == 'Article']\n",
    "        tweets = [doc for doc in old_docs if doc['genre'] == 'Tweet']\n",
    "        \n",
    "        for docs in [articles, tweets]:\n",
    "            if method == 'random':\n",
    "                random.shuffle(docs)\n",
    "            elif method == 'greedy':\n",
    "                docs = sorted(docs, key=lambda x: len(x['text']), reverse=True)\n",
    "            new_doc = None\n",
    "            for doc in docs:\n",
    "                if new_doc is None:\n",
    "                    new_doc = doc\n",
    "                else:\n",
    "                    new_doc['text'] += f'<new> {doc[\"text\"]}'\n",
    "                if len(new_doc['text']) >= threshold:\n",
    "                    text = new_doc['text']\n",
    "                    # only want to create multiple pairs from same datum in train setup\n",
    "                    for i in range(0, max(len(text) // upper_char_limit, 1) if not is_test else 1):\n",
    "                        new_doc['text'] = text[upper_char_limit*i:upper_char_limit*(i+1)]\n",
    "                        if len(new_doc['text']) >= threshold:\n",
    "                            new_authors[author].append(copy.deepcopy(new_doc))\n",
    "                    new_doc = None\n",
    "    return new_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 5665\n",
      "Articles per author: total: 158984 count: 5614 mean: 28.319 quartiles: 2.0/4.0/17.0 std: 112.14\n",
      "Chars per article per author: total: 42858989.0 count: 5614 mean: 7634.305 quartiles: 3158.0/5503.0/8810.329 std: 8183.977\n",
      "Tweets per author: total: 1043732 count: 1925 mean: 542.198 quartiles: 500.0/600.0/600.0 std: 371.168\n",
      "Chars per tweet per author: total: 236446.0 count: 1925 mean: 122.829 quartiles: 91.49/116.665/149.153 std: 42.284\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(silver_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 5665\n",
      "Articles per author: total: 355047 count: 5610 mean: 63.288 quartiles: 3.0/12.0/43.0 std: 216.016\n",
      "Chars per article per author: total: 12344966.0 count: 5610 mean: 2200.529 quartiles: 2194.083/2481.302/2500.0 std: 530.454\n",
      "Tweets per author: total: 237174 count: 1900 mean: 124.828 quartiles: 80.0/117.0/153.25 std: 101.02\n",
      "Chars per tweet per author: total: 1078316.0 count: 1900 mean: 567.535 quartiles: 559.752/568.952/576.468 std: 13.842\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(stack_documents(silver_authors, 500, method='greedy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 337\n",
      "Articles per author: total: 58563 count: 337 mean: 173.777 quartiles: 100.0/100.0/250.0 std: 160.576\n",
      "Chars per article per author: total: 1149009.0 count: 337 mean: 3409.523 quartiles: 267.45/374.27/5753.864 std: 4751.575\n",
      "Tweets per author: total: 108841 count: 337 mean: 322.97 quartiles: 100.0/100.0/600.0 std: 260.896\n",
      "Chars per tweet per author: total: 50401.0 count: 337 mean: 149.558 quartiles: 94.492/141.16/211.67 std: 59.551\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(gold_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 337\n",
      "Articles per author: total: 48219 count: 337 mean: 143.083 quartiles: 43.0/54.0/249.0 std: 175.025\n",
      "Chars per article per author: total: 490332.0 count: 337 mean: 1454.992 quartiles: 625.6/690.919/2476.576 std: 893.271\n",
      "Tweets per author: total: 25228 count: 337 mean: 74.861 quartiles: 34.0/41.0/115.0 std: 59.273\n",
      "Chars per tweet per author: total: 194301.0 count: 337 mean: 576.561 quartiles: 564.259/575.409/588.7 std: 18.603\n"
     ]
    }
   ],
   "source": [
    "print_author_statistics(stack_documents(gold_authors, 500, method='greedy', is_test=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document genre: Article\n",
      "Document length: 26272\n",
      "The Culture Issue\n",
      "Sex, Death, Family: <PERSON> Is Still Shockingly Intimate\n",
      "“No one should read more than one poem at a time from this book.”\n",
      "To hear more audio stories from publications like The New York Times, download Audm for iPhone or Android.\n",
      "If you have ever studied poetry — if perhaps you we\n"
     ]
    }
   ],
   "source": [
    "print_example(gold_authors, random.choice(tuple(gold_filtered)), genre='Tweet')\n",
    "print_example(silver_authors, random.choice(tuple(silver_filtered)), genre='Article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_golds = stack_documents(gold_authors, 500, method='greedy', is_test=True)\n",
    "stacked_silvers = stack_documents(silver_authors, 500, method='greedy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_verification_pairs(data, first_genre, second_genre):\n",
    "    data = copy.deepcopy(data)\n",
    "    first_docs = {\n",
    "        author_name: [doc for doc in author_docs if doc['genre'] == first_genre]\n",
    "            for author_name, author_docs in data.items()\n",
    "    }\n",
    "    if first_genre == second_genre:\n",
    "        second_docs = first_docs\n",
    "    else:\n",
    "        second_docs = {\n",
    "            author_name: [doc for doc in author_docs if doc['genre'] == second_genre]\n",
    "                for author_name, author_docs in data.items()\n",
    "        }\n",
    "        \n",
    "    delete_threshold = 0 if first_genre != second_genre else 1\n",
    "        \n",
    "    for author in data.keys():\n",
    "        random.shuffle(first_docs[author])\n",
    "        random.shuffle(second_docs[author])\n",
    "        \n",
    "        if len(first_docs[author]) <= delete_threshold:\n",
    "            del first_docs[author]\n",
    "        if len(second_docs[author]) <= delete_threshold:\n",
    "            del second_docs[author]\n",
    "    \n",
    "    # each pair is a 3-tuple of (label, first_text, second_text), where label == 0 if different authors and 1 if same author\n",
    "    pairs = []\n",
    "   \n",
    "    next_pick = 'same'\n",
    "    # need at least two authors for each genre to pick pairs\n",
    "    while len(first_docs) > 1 and len(second_docs) > 1:\n",
    "        # pick authors for next pair\n",
    "        first_author_pool = list(first_docs.keys())\n",
    "        second_author_pool = list(second_docs.keys())\n",
    "        if next_pick == 'diff':\n",
    "            first_author = random.choice(first_author_pool)\n",
    "            second_author = random.choice(second_author_pool)\n",
    "            while first_author == second_author:\n",
    "                second_author = random.choice(second_author_pool)\n",
    "        elif next_pick == 'same':\n",
    "            first_author = random.choice(first_author_pool)\n",
    "            # try picking 10 random authors, if this doesn't work, then iterate through all authors\n",
    "            if first_author not in second_author_pool:\n",
    "                for _ in range(10):\n",
    "                    first_author = random.choice(first_author_pool)\n",
    "                    if first_author in second_author_pool:\n",
    "                        break\n",
    "            if first_author not in second_author_pool:\n",
    "                random.shuffle(first_author_pool)\n",
    "                found_same_author = False\n",
    "                for author in first_author_pool:\n",
    "                    if author in second_author_pool:\n",
    "                        first_author = author\n",
    "                        found_same_author = True\n",
    "                        break\n",
    "                if not found_same_author:\n",
    "                    break # bailing, no same authors left\n",
    "            second_author = first_author\n",
    "        \n",
    "        if len(first_docs[first_author]) == 0 or len(second_docs[second_author]) == 0:\n",
    "            print(first_author, second_author, len(first_docs[first_author]), len(second_docs[second_author]))\n",
    "        pairs.append((1 if next_pick == 'same' else 0, first_docs[first_author].pop()['text'], second_docs[second_author].pop()['text'], first_author, second_author))\n",
    "        \n",
    "        if len(first_docs[first_author]) <= delete_threshold:\n",
    "            del first_docs[first_author]\n",
    "        if (first_genre != second_genre or first_author != second_author) and len(second_docs[second_author]) <= delete_threshold:\n",
    "            del second_docs[second_author]\n",
    "                \n",
    "        # alternate pair type\n",
    "        next_pick = 'diff' if next_pick == 'same' else 'same'\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pair_stats(pairs, save=None):\n",
    "    print(f'Total pairs: {len(pairs)}; same-pair percent: {sum([pair[0] for pair in pairs]) / len(pairs)}')\n",
    "    \n",
    "    authors = set()\n",
    "    first_genre_lengths, second_genre_lengths = [], []\n",
    "    for pair in pairs:\n",
    "        first_length, second_length = len(pair[1]), len(pair[2])\n",
    "        first_author, second_author = pair[3], pair[4]\n",
    "        authors.add(first_author)\n",
    "        authors.add(second_author)\n",
    "        first_genre_lengths.append(first_length)\n",
    "        second_genre_lengths.append(second_length)\n",
    "    \n",
    "    print(f'Num authors: {len(authors)}')\n",
    "    print(f'Avg. chars per first genre: {sum(first_genre_lengths) / len(first_genre_lengths)}')\n",
    "    print(f'Avg. chars per second genre: {sum(second_genre_lengths) / len(second_genre_lengths)}')\n",
    "    \n",
    "    if save:\n",
    "        print(f'Saving to {save}.')\n",
    "        columns = ['label', 'text0', 'text1']\n",
    "        df = pd.DataFrame([(pair[0], pair[1], pair[2]) for pair in pairs], columns=columns)\n",
    "        df.to_csv(save, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[265], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m test_pairs_Article_Article \u001b[38;5;241m=\u001b[39m create_verification_pairs(stacked_golds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArticle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArticle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m test_pairs_X_X \u001b[38;5;241m=\u001b[39m create_verification_pairs(stacked_golds, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTweet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTweet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m train_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_verification_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacked_silvers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mArticle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTweet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[263], line 41\u001b[0m, in \u001b[0;36mcreate_verification_pairs\u001b[1;34m(data, first_genre, second_genre)\u001b[0m\n\u001b[0;32m     39\u001b[0m         second_author \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoice(second_author_pool)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m next_pick \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 41\u001b[0m     first_author \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_author_pool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# try picking 10 random authors, if this doesn't work, then iterate through all authors\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_author \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m second_author_pool:\n",
      "File \u001b[1;32mc:\\Users\\mamar\\anaconda3\\envs\\authorship\\Lib\\random.py:348\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_randbelow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Users\\mamar\\anaconda3\\envs\\authorship\\Lib\\random.py:242\u001b[0m, in \u001b[0;36mRandom._randbelow_with_getrandbits\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow_without_getrandbits\n\u001b[0;32m    240\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_randbelow_with_getrandbits\u001b[39m(\u001b[38;5;28mself\u001b[39m, n):\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn a random int in the range [0,n).  Defined for n > 0.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m     getrandbits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetrandbits\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_pairs_Article_X = create_verification_pairs(stacked_golds, 'Article', 'Tweet')\n",
    "test_pairs_Article_Article = create_verification_pairs(stacked_golds, 'Article', 'Article')\n",
    "test_pairs_X_X = create_verification_pairs(stacked_golds, 'Tweet', 'Tweet')\n",
    "train_pairs = create_verification_pairs(stacked_silvers, 'Article', 'Tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 25162; same-pair percent: 0.5\n",
      "Num authors: 337\n",
      "Avg. chars per first genre: 1842.4398299022334\n",
      "Avg. chars per second genre: 574.0502344805659\n",
      "Saving to pairs/test_Article_X.csv.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('pairs', exist_ok=True)\n",
    "print_pair_stats(test_pairs_Article_X, save='pairs/test_Article_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 104104; same-pair percent: 0.5\n",
      "Num authors: 5662\n",
      "Avg. chars per first genre: 2311.9295127948976\n",
      "Avg. chars per second genre: 569.2524590793821\n"
     ]
    }
   ],
   "source": [
    "print_pair_stats(test_pairs_Article_Article, save='pairs/test_Article_Article.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pair_stats(test_pairs_X_X, save='pairs/test_X_X.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_pair_stats(train_pairs, save='pairs/train_Article_X.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
